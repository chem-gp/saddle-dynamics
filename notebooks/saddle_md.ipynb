{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import gpytorch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from ase import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../fande\") # Adds higher directory to python modules path.\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.data import FandeDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing and loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sdynamics.load import parse_trajectories, parse_forces, flatten_trj_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading trajectory files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:18<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory files reading done!\n",
      "Reading .npy files with forces...\n",
      "Reading .npy files with forces done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trajectories, energies_trj, trj_files_basenames = parse_trajectories(traj_folder=\"../data/dynamics/ene_grad_fitting/data/trj/\")\n",
    "forces_trj = parse_forces(forces_path = '../data/dynamics/ene_grad_fitting/data/grad/', trj_files_basenames = trj_files_basenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening done!\n"
     ]
    }
   ],
   "source": [
    "traj, energies, forces = flatten_trj_dictionaries(trajectories, energies_trj, trj_files_basenames, forces_trj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training/test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data:\n",
    "# training_indices = np.sort(  np.random.choice(np.arange(0,10_000), 10000, replace=False) )\n",
    "training_indices = np.sort(  np.arange(0, 90_000, 500) )  \n",
    "traj_train = [traj[i] for i in training_indices]\n",
    "energies_train = energies[training_indices]\n",
    "forces_train = forces[training_indices]\n",
    "train_data = {'trajectory': traj_train, 'energies': energies_train, 'forces': forces_train}\n",
    "\n",
    "#Test data:\n",
    "# test_indices = np.sort(  np.random.choice(np.arange(0,92795), 200, replace=False) ) \n",
    "test_indices = np.sort(  np.arange(0,1_000,1) ) \n",
    "traj_test = [traj[i] for i in test_indices]\n",
    "energies_test = energies[test_indices]\n",
    "forces_test = forces[test_indices]\n",
    "test_data = {'trajectory': traj_test, 'energies': energies_test, 'forces': forces_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fande.data import FandeDataModuleASE\n",
    "\n",
    "\n",
    "hparams = {\n",
    "    'dtype' : 'float64',\n",
    "    'device' : 'gpu'\n",
    "}\n",
    "\n",
    "fdm = FandeDataModuleASE(train_data, test_data, hparams, atoms_forces=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of train traj is 180\n",
      "Starting SOAP calculation...\n",
      "SOAP calculation done!\n",
      "Total length of test traj is 1000\n",
      "Starting SOAP calculation...\n",
      "SOAP calculation done!\n",
      "(180, 17, 3, 330)\n",
      "(180, 330)\n"
     ]
    }
   ],
   "source": [
    "soap_params = {\n",
    "    'species': [\"H\", \"C\"],\n",
    "    'periodic': False,\n",
    "    'rcut': 3.0,\n",
    "    'sigma': 0.5,\n",
    "    'nmax': 5,\n",
    "    'lmax': 5,\n",
    "    'average': \"outer\",\n",
    "    'crossover': True,\n",
    "    'dtype': \"float64\",\n",
    "    'n_jobs': 10,\n",
    "    'sparse': False,\n",
    "    'positions': [0,2,3,6]\n",
    "}\n",
    "\n",
    "fdm.calculate_invariants(soap_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9180, 330])"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdm.train_DX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Forces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/dlb/anaconda3/envs/pyc/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1566: UserWarning:\n",
      "\n",
      "GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "\n",
      "\n",
      "   | Name                                                      | Type                       | Params\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "0  | likelihood                                                | GaussianLikelihood         | 1     \n",
      "1  | likelihood.noise_covar                                    | HomoskedasticNoise         | 1     \n",
      "2  | likelihood.noise_covar.raw_noise_constraint               | GreaterThan                | 0     \n",
      "3  | likelihood.noise_covar.raw_noise_constraint._transform    | Softplus                   | 0     \n",
      "4  | model                                                     | ExactGPModelForces         | 333   \n",
      "5  | model.covar_module                                        | ScaleKernel                | 331   \n",
      "6  | model.covar_module.base_kernel                            | RBFKernel                  | 330   \n",
      "7  | model.covar_module.base_kernel.raw_lengthscale_constraint | Positive                   | 0     \n",
      "8  | model.covar_module.raw_outputscale_constraint             | Positive                   | 0     \n",
      "9  | model.mean_module                                         | ConstantMean               | 1     \n",
      "10 | mll                                                       | ExactMarginalLogLikelihood | 333   \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "333       Trainable params\n",
      "0         Non-trainable params\n",
      "333       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "/home/dlb/anaconda3/envs/pyc/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning:\n",
      "\n",
      "The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 28 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "\n",
      "/home/dlb/anaconda3/envs/pyc/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:394: UserWarning:\n",
      "\n",
      "The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " setup() callback called...\n",
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it, loss=0.708, v_num=183]\n",
      "\n",
      " teardown() callback called...\n"
     ]
    }
   ],
   "source": [
    "from fande.models import ModelForces, ModelEnergies, MyCallbacks\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import numpy as np\n",
    "# seed_everything(42, workers=True)\n",
    "\n",
    "train_DX = fdm.train_DX\n",
    "train_F = fdm.train_F\n",
    "test_DX = fdm.test_DX\n",
    "test_F = fdm.test_F\n",
    "\n",
    "# ind_slice = np.sort( np.concatenate( \n",
    "#     ( np.arange(0,4800), np.arange(11*4800,12*4800), np.random.choice(np.arange(4800,59200), 300, replace=False) ) \n",
    "#     ) )\n",
    "\n",
    "# ind_slice = np.sort(  np.random.choice(np.arange(0,train_F.shape[0]), 2_000, replace=False) ) \n",
    "# ind_slice = np.sort(  np.arange(0,2550) ) \n",
    "ind_slice = np.sort(  np.arange(0,train_F.shape[0]) ) \n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(train_DX[ind_slice], train_F[ind_slice])\n",
    "train_loader = DataLoader(train_dataset, batch_size=100_000)\n",
    "\n",
    "model_f = ModelForces(train_DX[ind_slice], train_F[ind_slice], hparams, 0.05)\n",
    "\n",
    "trainer_f = Trainer(\n",
    "    gpus=0, \n",
    "    max_epochs=10, \n",
    "    precision=64,\n",
    "    weights_summary='full', \n",
    "    callbacks=[MyCallbacks()])\n",
    "\n",
    "trainer_f.fit(model_f, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3) [[0.03557588 0.02658165 0.02494853]\n",
      " [0.08654764 0.01939834 0.0330811 ]\n",
      " [0.04102013 0.02392031 0.02153549]\n",
      " [0.06177905 0.02531317 0.02900263]\n",
      " [0.01348011 0.01000791 0.01814585]\n",
      " [0.01911702 0.01420778 0.01322842]\n",
      " [0.01224534 0.01147615 0.00967989]\n",
      " [0.01266411 0.00939868 0.01064205]\n",
      " [0.01436309 0.00920342 0.01047329]\n",
      " [0.01263888 0.01136476 0.01360414]\n",
      " [0.01316529 0.01234817 0.01075965]\n",
      " [0.01782208 0.01375587 0.01647894]\n",
      " [0.01459548 0.01162721 0.02730875]\n",
      " [0.01009001 0.01038885 0.0120274 ]\n",
      " [0.01072296 0.01038919 0.00978262]\n",
      " [0.0073473  0.00807979 0.00805806]\n",
      " [0.0085479  0.00731232 0.00852278]]\n"
     ]
    }
   ],
   "source": [
    "from fande.predict import PredictorASE\n",
    "\n",
    "test_X = fdm.test_X\n",
    "test_DX = fdm.test_DX\n",
    "test_E = fdm.test_E\n",
    "test_F = fdm.test_F\n",
    "\n",
    "model_e = None\n",
    "trainer_e = None\n",
    "\n",
    "\n",
    "predictor = PredictorASE(\n",
    "            model_e,\n",
    "            model_f,\n",
    "            trainer_e,\n",
    "            trainer_f,\n",
    "            test_X,\n",
    "            test_DX,\n",
    "            test_E,\n",
    "            test_F,\n",
    "            test_data,\n",
    "            hparams,\n",
    "            soap_params\n",
    ")\n",
    "\n",
    "\n",
    "# predictor.predict_and_plot_forces()\n",
    "mol = fdm.traj_test[0].copy()\n",
    "# f_, f_var_ = predictor.predict_forces_single(mol)\n",
    "\n",
    "print(f_.shape, f_var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SOAP calculation...\n",
      "SOAP calculation done!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must train on the training inputs!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mセル19 を /home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb#Y154sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dx \u001b[39m=\u001b[39m dx\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb#Y154sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# print(dx.device)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb#Y154sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# mf_cpu = model_f.cpu()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb#Y154sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# mf_cpu.model(dx)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dlb/coding/shared_coding/repos/chem-gp/saddle-dynamics/notebooks/saddle_md.ipynb#Y154sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_f\u001b[39m.\u001b[39;49mmodel(dx)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyc/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:259\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mon():\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(torch\u001b[39m.\u001b[39mequal(train_input, \u001b[39minput\u001b[39m) \u001b[39mfor\u001b[39;00m train_input, \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(train_inputs, inputs)):\n\u001b[0;32m--> 259\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must train on the training inputs!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    260\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    261\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must train on the training inputs!"
     ]
    }
   ],
   "source": [
    "x,dx = predictor.soap_single(mol)\n",
    "\n",
    "dx = dx.cpu()\n",
    "# print(dx.device)\n",
    "# mf_cpu = model_f.cpu()\n",
    "# mf_cpu.model(dx)\n",
    "model_f.model(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelForces(\n",
       "  (likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (model): ExactGPModelForces(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "        (distance_module): Distance()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPModelForces(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): RBFKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "          (distance_module): Distance()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "      (mean_module): ConstantMean()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamics simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdynamics.dynamics import MDynamics\n",
    "\n",
    "atoms = ... # initialize saddle structure\n",
    "\n",
    "atoms.calc = gp_model.ase_calc() # get calc from the trained GP\n",
    "\n",
    "md_runner = MDynamics(atoms) # instantiate class for running MD\n",
    "\n",
    "md_runner.run() # run the MD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ASE calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from fande.ase import FandeCalc\n",
    "from ase.build import molecule\n",
    "\n",
    "from ase import io\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "\n",
    "traj = fdm.mol_traj #io.read(\"data/dump/mol_trj.xyz\", index=\":\")\n",
    "atoms = traj[0]\n",
    "\n",
    "# atoms = molecule(\"CH3CH2OCH3\")\n",
    "fande_calc = FandeCalc(hparams, model_e, trainer_e, model_f, trainer_f)\n",
    "\n",
    "for a in traj: a.calc=fande_calc \n",
    "\n",
    "print(atoms.get_potential_energy() )\n",
    "print( atoms.get_forces())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Molecular Dynamics with Fande calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from fande.ase import MDRunner\n",
    "\n",
    "atoms = fdm.mol_traj[10].copy()\n",
    "atoms.calc = FandeCalc(hparams, model_e, trainer_e, model_f, trainer_f)\n",
    "\n",
    "mdr = MDRunner(atoms, \"data/dump/ase/md_test.xyz\", \"data/dump/ase/md_log.log\")\n",
    "mdr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['/home/dlb/anaconda3/envs/pyc/bin/python', '...>"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ase.visualize import view\n",
    "\n",
    "# trj = trajectories[trj_files_basename[2]]\n",
    "view(traj[0:100])\n",
    "# view(traj[0:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ddd1365f44c090590bb2618f275add86752e536c29796713a70da7809cd2e3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
